{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad417aee",
   "metadata": {},
   "source": [
    "# Importing pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81ec912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pickle\n",
    "import time\n",
    "from src.datahandle import *\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cffa89",
   "metadata": {},
   "source": [
    "# Setting up hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5713f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper\n",
    "directory = '../../extras/data/A_training_given/training_data/'\n",
    "training_folder = 'training_data'\n",
    "training_labels_file= 'training_norm.csv'\n",
    "#\n",
    "collected_directory = '../../extras/data/Z_collected_raw/' \n",
    "#\n",
    "quiz_directory = '../../extras/data/C_testing_given/test_data/'\n",
    "quiz_training_folder = 'test_data'\n",
    "#configurations\n",
    "conf_tracking = 0\n",
    "seed = 0\n",
    "data_shape = 'original'\n",
    "parameter_init_scale = 0.01\n",
    "split= 0.8\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b297e6b",
   "metadata": {},
   "source": [
    "# Setting up DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8112d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloading object\n",
    "training_object= DataLoader(\n",
    "        directory,\n",
    "        training_folder,\n",
    "        training_labels_file\n",
    "        )\n",
    "collected_object = DataLoader(\n",
    "        collected_directory        \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee6f57",
   "metadata": {},
   "source": [
    "# Loading data information (not loading images yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f0219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_train, collected_test = collected_object.LoadCollectedData_info(\n",
    "        split=split,\n",
    "        batch_size=batch_size #for tf this batch size remains as 1\n",
    "        )\n",
    "#train test split\n",
    "train,test = training_object.LoadModelData_info(\n",
    "        split = split, \n",
    "        batch_size =batch_size)#for tf this batch size remains as 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016749e",
   "metadata": {},
   "source": [
    "# Stacking collected and kaggle given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b7b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XY = np.vstack((train,collected_train))\n",
    "test_XY= np.vstack((test[0],collected_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77456a",
   "metadata": {},
   "source": [
    "# Checking DataLoading functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "033ea7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    test_batch_X,test_batch_Y = training_object.Load_batch(train_XY[i], data_shape=data_shape)\n",
    "image_shape = test_batch_X.shape[1:]\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0d6c8",
   "metadata": {},
   "source": [
    "# Setting up data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453a83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "        layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        #layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f7c26",
   "metadata": {},
   "source": [
    "# Basic cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6feed790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model initialisation\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=image_shape),\n",
    "        data_augmentation,\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        data_augmentation,\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(2)\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38f2c539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x15bb6f1f0>,\n",
       " <keras.engine.sequential.Sequential at 0x158d35340>,\n",
       " <keras.layers.core.tf_op_layer.TFOpLambda at 0x159b9f940>,\n",
       " <keras.layers.core.tf_op_layer.TFOpLambda at 0x159b9f400>,\n",
       " <keras.engine.functional.Functional at 0x15a4b0ac0>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x15b6098b0>,\n",
       " <keras.layers.core.dropout.Dropout at 0x15bb6f190>,\n",
       " <keras.layers.core.dense.Dense at 0x15b72a220>,\n",
       " <keras.layers.core.dense.Dense at 0x15b609970>,\n",
       " <keras.layers.core.dense.Dense at 0x15b609af0>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de7fd5",
   "metadata": {},
   "source": [
    "# Weights and Biases configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6be93b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ai/Desktop/pycar/APP/Tensorflow_cnn/wandb/run-20220414_131356-15k0l9i7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mo379/Autonomous-driving/runs/15k0l9i7\" target=\"_blank\">pleasant-waterfall-137</a></strong> to <a href=\"https://wandb.ai/mo379/Autonomous-driving\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wandb tracking\n",
    "if conf_tracking:\n",
    "   config = {\n",
    "     \"model_type\" : 'Same convnet as submission 2 ,leaky relu, collected, data augmentation, dropoutlayer',\n",
    "     \"param_initialisation_scale\" : parameter_init_scale,\n",
    "     \"model_shape\" : str(model.layers),\n",
    "     \"learning_rate\": lr,\n",
    "     \"data_split\": split,\n",
    "     \"batch_size\": batch_size,\n",
    "     \"data_shape\" : str(data_shape),\n",
    "     \"epochs\": n_epochs,\n",
    "   }\n",
    "run = wandb.init(project=\"Autonomous-driving\", entity=\"mo379\",config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe424f",
   "metadata": {},
   "source": [
    "# Training Loop (With wandb logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec08a8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Could not synchronize CUDA stream: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_XY)):\n\u001b[1;32m      6\u001b[0m     X,Y \u001b[38;5;241m=\u001b[39m training_object\u001b[38;5;241m.\u001b[39mLoad_batch(train_XY[i], data_shape\u001b[38;5;241m=\u001b[39mdata_shape)\n\u001b[0;32m----> 7\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[1;32m      9\u001b[0m     X,Y \u001b[38;5;241m=\u001b[39m training_object\u001b[38;5;241m.\u001b[39mLoad_batch(test_batches[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m9\u001b[39m)], data_shape\u001b[38;5;241m=\u001b[39mdata_shape)\n\u001b[1;32m     10\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtest_on_batch(\n\u001b[1;32m     11\u001b[0m         X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reset_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/keras/engine/training.py:2095\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2092\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m   2093\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m-> 2095\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n\u001b[1;32m   2097\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m logs\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1191\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numpy_internal()\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1191\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInternalError\u001b[0m: Could not synchronize CUDA stream: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "model_path = 'pkls/tf_cnn_augmented.pkl'\n",
    "#model = tf.keras.models.load_model(model_path, custom_objects=None, compile=True, options=None)\n",
    "test_batches = test_XY[0:2930].reshape(10,-1,4)\n",
    "for _ in range(n_epochs):\n",
    "    for i in range(len(train_XY)):\n",
    "        X,Y = training_object.Load_batch(train_XY[i], data_shape=data_shape)\n",
    "        train_metrics = model.train_on_batch(X,Y, return_dict=True) \n",
    "\n",
    "        X,Y = training_object.Load_batch(test_batches[np.random.randint(0,9)], data_shape=data_shape)\n",
    "        test_metrics = model.test_on_batch(\n",
    "            X, Y, sample_weight=None, reset_metrics=True, return_dict=True\n",
    "        )\n",
    "        \n",
    "        if conf_tracking==1:\n",
    "            wandb.log({\"test_loss\": test_metrics['loss']})\n",
    "            wandb.log({\"batch_loss\": train_metrics['loss']})\n",
    "\n",
    "            wandb.log({\"test_accuracy\": test_metrics['accuracy']})\n",
    "            wandb.log({\"batch_accuracy\": train_metrics['accuracy']})\n",
    "#tf.keras.models.save_model(\n",
    "#    model,\n",
    "#    model_path,\n",
    "#    overwrite=False,\n",
    "#    include_optimizer=True,\n",
    "#    save_format=None,\n",
    "#    signatures=None,\n",
    "#    options=None,\n",
    "#    save_traces=True\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def0ecb",
   "metadata": {},
   "source": [
    "# Loading the Quiz data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_object= DataLoader(\n",
    "    quiz_directory,\n",
    "    quiz_training_folder,\n",
    ")\n",
    "quiz_train = quiz_object.LoadQuizData_info()\n",
    "X,image_order = quiz_object.Load_batch_quiz(quiz_train,data_shape=data_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab7204",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prds = model.predict(X)\n",
    "final_prd = np.column_stack((image_order,prds))\n",
    "final_ordered = final_prd[final_prd[:, 0].argsort()]\n",
    "df = pd.DataFrame(final_ordered, columns = ['image_id','angle','speed'])\n",
    "df = df.astype({'image_id': 'int32'})\n",
    "df.to_csv('submission.csv', index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7d1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlis_car",
   "language": "python",
   "name": "mlis_car"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
