{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad417aee",
   "metadata": {},
   "source": [
    "# Importing pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81ec912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pickle\n",
    "import time\n",
    "from src.datahandle import *\n",
    "import time\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cffa89",
   "metadata": {},
   "source": [
    "# Setting up hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5713f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper\n",
    "directory = '../../extras/data/A_training_given/training_data/'\n",
    "training_folder = 'training_data'\n",
    "training_labels_file= 'training_norm.csv'\n",
    "#\n",
    "collected_directory = '../../extras/data/Z_collected_raw/' \n",
    "#\n",
    "quiz_directory = '../../extras/data/C_testing_given/test_data/'\n",
    "quiz_training_folder = 'test_data'\n",
    "#configurations\n",
    "conf_tracking = 1\n",
    "seed = 0\n",
    "data_shape = 'original'\n",
    "parameter_init_scale = 0.01\n",
    "split= 0.8\n",
    "batch_size = 256\n",
    "n_epochs = 8\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b297e6b",
   "metadata": {},
   "source": [
    "# Setting up DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8112d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloading object\n",
    "training_object= DataLoader(\n",
    "        directory,\n",
    "        training_folder,\n",
    "        training_labels_file\n",
    "        )\n",
    "collected_object = DataLoader(\n",
    "        collected_directory        \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee6f57",
   "metadata": {},
   "source": [
    "# Loading data information (not loading images yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f0219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_train, collected_test = collected_object.LoadCollectedData_info(\n",
    "        split=split,\n",
    "        batch_size=batch_size #for tf this batch size remains as 1\n",
    "        )\n",
    "#train test split\n",
    "train,test = training_object.LoadModelData_info(\n",
    "        split = split, \n",
    "        batch_size =batch_size)#for tf this batch size remains as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c24fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['../../extras/data/Z_collected_raw/1648217084653_90_35.png',\n",
       "        '1648217084653', '0.571', '0.899'], dtype='<U58'),\n",
       " array([['../../extras/data/A_training_given/training_data/training_data/11705.png',\n",
       "         '11705', '0.625', '0.885'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/7262.png',\n",
       "         '7262', '0.6875', '0.052'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/6443.png',\n",
       "         '6443', '0.75', '0.965'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/6877.png',\n",
       "         '6877', '0.75', '0.886'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/5105.png',\n",
       "         '5105', '0.5', '0.946'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/2186.png',\n",
       "         '2186', '0.6875', '0.929'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/10661.png',\n",
       "         '10661', '0.75', '0.893'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/4796.png',\n",
       "         '4796', '0.6875', '0.965'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/11000.png',\n",
       "         '11000', '0.5', '0.075']], dtype='<U72'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_train[0][1],train[1][1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016749e",
   "metadata": {},
   "source": [
    "# Stacking collected and kaggle given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b7b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XY = train #np.vstack((train,collected_train))\n",
    "test_XY= test[0] #np.vstack((test[0],collected_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77456a",
   "metadata": {},
   "source": [
    "# Checking DataLoading functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033ea7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    test_batch_X,test_batch_Y = training_object.Load_batch(train_XY[i], data_shape=data_shape)\n",
    "image_shape = test_batch_X.shape[1:]\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0d6c8",
   "metadata": {},
   "source": [
    "# Setting up data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453a83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "        layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        #layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb5ee0",
   "metadata": {},
   "source": [
    "# Setting up preprocessing for MobilenetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4832273",
   "metadata": {},
   "source": [
    "# Transfer Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e56a9",
   "metadata": {},
   "source": [
    "## to do\n",
    "- [x] Seperate TF_cnn from TF_transfer\n",
    "- [x] Remove rescaling in datahandling step (Now done by the preprocess layer)\n",
    "- [x] Correctly rescale collected images labels (speed and angle)\n",
    "- [x] Soften output\n",
    "- [ ] Train the transfer learning model\n",
    "- [ ] Tune the transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06442fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.efficientnet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ec2cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Base = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(input_shape=image_shape,include_top=False,weights='imagenet')\n",
    "Base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1808ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "inference_layer = tf.keras.layers.Dense(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f041b4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = training_object.Load_batch(train_XY[0], data_shape=data_shape)\n",
    "preprocess_input(example_batch[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b0d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=image_shape)\n",
    "x = preprocess_input(inputs)\n",
    "x = Base(inputs)\n",
    "x = global_average_layer(x)\n",
    "outputs = inference_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f2c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 240, 320, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 8, 10, 1280)      5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,921,874\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de7fd5",
   "metadata": {},
   "source": [
    "# Weights and Biases configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6be93b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmo379\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ai/Desktop/pycar/APP/Tensorflow_transfer_mobilenet/wandb/run-20220415_133738-1fidebfj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mo379/Autonomous-driving/runs/1fidebfj\" target=\"_blank\">royal-snowball-169</a></strong> to <a href=\"https://wandb.ai/mo379/Autonomous-driving\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wandb tracking\n",
    "if conf_tracking:\n",
    "    config = {\n",
    "     \"model_type\" : 'Transfer Learning with MobileNetV2',\n",
    "     \"model_shape\" : str(model.layers),\n",
    "     \"learning_rate\": lr,\n",
    "     \"data_split\": split,\n",
    "     \"batch_size\": batch_size,\n",
    "     \"epochs\": n_epochs,\n",
    "    }\n",
    "    run = wandb.init(project=\"Autonomous-driving\", entity=\"mo379\",config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe424f",
   "metadata": {},
   "source": [
    "# Training Loop (With wandb logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec08a8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Could not synchronize CUDA stream: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     X_test,Y_test \u001b[38;5;241m=\u001b[39m training_object\u001b[38;5;241m.\u001b[39mLoad_batch(test_batches[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m9\u001b[39m)], data_shape\u001b[38;5;241m=\u001b[39mdata_shape)\n\u001b[0;32m---> 10\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_on_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m conf_tracking\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     15\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/keras/engine/training.py:2152\u001b[0m, in \u001b[0;36mModel.test_on_batch\u001b[0;34m(self, x, y, sample_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2149\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_test_function()\n\u001b[1;32m   2150\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[0;32m-> 2152\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n\u001b[1;32m   2154\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m logs\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/anaconda3/envs/pycar/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1191\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numpy_internal()\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1191\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInternalError\u001b[0m: Could not synchronize CUDA stream: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "model_path = 'pkls/tf_cnn_augmented.pkl'\n",
    "#model = tf.keras.models.load_model(model_path, custom_objects=None, compile=True, options=None)\n",
    "test_batches = test_XY[0:2750].reshape(10,-1,4)\n",
    "for _ in range(n_epochs):\n",
    "    for i in range(len(train_XY)):\n",
    "        X,Y = training_object.Load_batch(train_XY[i], data_shape=data_shape)\n",
    "        train_metrics = model.train_on_batch(X,Y, return_dict=True) \n",
    "        if i % 3 == 0:\n",
    "            X_test,Y_test = training_object.Load_batch(test_batches[np.random.randint(0,9)], data_shape=data_shape)\n",
    "            test_metrics = model.test_on_batch(\n",
    "                X_test, Y_test, sample_weight=None, reset_metrics=False, return_dict=True\n",
    "            )\n",
    "        \n",
    "            if conf_tracking==1:\n",
    "                wandb.log({\"test_loss\": test_metrics['loss']})\n",
    "                wandb.log({\"batch_loss\": train_metrics['loss']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c5d79ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>█▃▃▂▂▁▂▁▁▁</td></tr><tr><td>test_loss</td><td>█▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.07282</td></tr><tr><td>test_loss</td><td>0.06789</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">royal-snowball-169</strong>: <a href=\"https://wandb.ai/mo379/Autonomous-driving/runs/1fidebfj\" target=\"_blank\">https://wandb.ai/mo379/Autonomous-driving/runs/1fidebfj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_133738-1fidebfj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    model_path,\n",
    "    overwrite=False,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None,\n",
    "    save_traces=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def0ecb",
   "metadata": {},
   "source": [
    "# Loading the Quiz data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_object= DataLoader(\n",
    "    quiz_directory,\n",
    "    quiz_training_folder,\n",
    ")\n",
    "quiz_train = quiz_object.LoadQuizData_info()\n",
    "X,image_order = quiz_object.Load_batch_quiz(quiz_train,data_shape=data_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab7204",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prds = model.predict(X)\n",
    "final_prd = np.column_stack((image_order,prds))\n",
    "final_ordered = final_prd[final_prd[:, 0].argsort()]\n",
    "df = pd.DataFrame(final_ordered, columns = ['image_id','angle','speed'])\n",
    "df = df.astype({'image_id': 'int32'})\n",
    "df.to_csv('transfer_MobileNetV3Small.csv', index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7d1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de125774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
