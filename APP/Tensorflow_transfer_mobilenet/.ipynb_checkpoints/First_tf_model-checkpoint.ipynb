{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad417aee",
   "metadata": {},
   "source": [
    "# Importing pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81ec912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pickle\n",
    "import time\n",
    "from src.datahandle import *\n",
    "import time\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cffa89",
   "metadata": {},
   "source": [
    "# Setting up hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5713f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper\n",
    "directory = '../../extras/data/A_training_given/training_data/'\n",
    "training_folder = 'training_data'\n",
    "training_labels_file= 'training_norm.csv'\n",
    "#\n",
    "collected_directory = '../../extras/data/Z_collected_raw/' \n",
    "#\n",
    "quiz_directory = '../../extras/data/C_testing_given/test_data/'\n",
    "quiz_training_folder = 'test_data'\n",
    "#configurations\n",
    "conf_tracking = 1\n",
    "seed = 0\n",
    "data_shape = 'original'\n",
    "parameter_init_scale = 0.01\n",
    "split= 0.8\n",
    "batch_size = 256\n",
    "n_epochs = 8\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b297e6b",
   "metadata": {},
   "source": [
    "# Setting up DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8112d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloading object\n",
    "training_object= DataLoader(\n",
    "        directory,\n",
    "        training_folder,\n",
    "        training_labels_file\n",
    "        )\n",
    "collected_object = DataLoader(\n",
    "        collected_directory        \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee6f57",
   "metadata": {},
   "source": [
    "# Loading data information (not loading images yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f0219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_train, collected_test = collected_object.LoadCollectedData_info(\n",
    "        split=split,\n",
    "        batch_size=batch_size #for tf this batch size remains as 1\n",
    "        )\n",
    "#train test split\n",
    "train,test = training_object.LoadModelData_info(\n",
    "        split = split, \n",
    "        batch_size =batch_size)#for tf this batch size remains as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c24fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['../../extras/data/Z_collected_raw/1648217084653_90_35.png',\n",
       "        '1648217084653', '0.571', '0.984'], dtype='<U58'),\n",
       " array([['../../extras/data/A_training_given/training_data/training_data/11705.png',\n",
       "         '11705', '0.625', '0.888'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/7262.png',\n",
       "         '7262', '0.6875', '0.111'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/6443.png',\n",
       "         '6443', '0.75', '0.878'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/6877.png',\n",
       "         '6877', '0.75', '0.99'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/5105.png',\n",
       "         '5105', '0.5', '0.953'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/2186.png',\n",
       "         '2186', '0.6875', '0.981'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/10661.png',\n",
       "         '10661', '0.75', '0.976'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/4796.png',\n",
       "         '4796', '0.6875', '0.914'],\n",
       "        ['../../extras/data/A_training_given/training_data/training_data/11000.png',\n",
       "         '11000', '0.5', '0.004']], dtype='<U72'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_train[0][1],train[1][1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016749e",
   "metadata": {},
   "source": [
    "# Stacking collected and kaggle given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b7b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XY = train #np.vstack((train,collected_train))\n",
    "test_XY= test[0] #np.vstack((test[0],collected_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77456a",
   "metadata": {},
   "source": [
    "# Checking DataLoading functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033ea7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    test_batch_X,test_batch_Y = training_object.Load_batch(train_XY[i], data_shape=data_shape)\n",
    "image_shape = test_batch_X.shape[1:]\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0d6c8",
   "metadata": {},
   "source": [
    "# Setting up data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453a83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "        layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        #layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb5ee0",
   "metadata": {},
   "source": [
    "# Setting up preprocessing for MobilenetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4832273",
   "metadata": {},
   "source": [
    "# Transfer Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e56a9",
   "metadata": {},
   "source": [
    "## to do\n",
    "- [x] Seperate TF_cnn from TF_transfer\n",
    "- [x] Remove rescaling in datahandling step (Now done by the preprocess layer)\n",
    "- [x] Correctly rescale collected images labels (speed and angle)\n",
    "- [x] Soften output\n",
    "- [ ] Train the transfer learning model\n",
    "- [ ] Tune the transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06442fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.efficientnet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ec2cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Base = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(input_shape=image_shape,include_top=False,weights='imagenet')\n",
    "Base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1808ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "inference_layer = tf.keras.layers.Dense(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a110185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = training_object.Load_batch(train_XY[0], data_shape=data_shape)\n",
    "preprocess_input(example_batch[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b0d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=image_shape)\n",
    "x = preprocess_input(inputs)\n",
    "x = Base(inputs)\n",
    "x = global_average_layer(x)\n",
    "outputs = inference_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f2c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 240, 320, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 8, 10, 1280)      5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,921,874\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de7fd5",
   "metadata": {},
   "source": [
    "# Weights and Biases configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6be93b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmo379\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ai/Desktop/pycar/APP/Tensorflow_transfer_mobilenet/wandb/run-20220415_132551-ocwj50vd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mo379/Autonomous-driving/runs/ocwj50vd\" target=\"_blank\">lucky-pyramid-168</a></strong> to <a href=\"https://wandb.ai/mo379/Autonomous-driving\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wandb tracking\n",
    "if conf_tracking:\n",
    "    config = {\n",
    "     \"model_type\" : 'Transfer Learning with MobileNetV2',\n",
    "     \"model_shape\" : str(model.layers),\n",
    "     \"learning_rate\": lr,\n",
    "     \"data_split\": split,\n",
    "     \"batch_size\": batch_size,\n",
    "     \"epochs\": n_epochs,\n",
    "    }\n",
    "    run = wandb.init(project=\"Autonomous-driving\", entity=\"mo379\",config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe424f",
   "metadata": {},
   "source": [
    "# Training Loop (With wandb logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec08a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'pkls/tf_cnn_augmented.pkl'\n",
    "#model = tf.keras.models.load_model(model_path, custom_objects=None, compile=True, options=None)\n",
    "test_batches = test_XY[0:2750].reshape(10,-1,4)\n",
    "for _ in range(n_epochs):\n",
    "    for i in range(len(train_XY)):\n",
    "        X,Y = training_object.Load_batch(train_XY[i], data_shape=data_shape)\n",
    "        train_metrics = model.train_on_batch(X,Y, return_dict=True) \n",
    "        if i % 3 == 0:\n",
    "            X_test,Y_test = training_object.Load_batch(test_batches[np.random.randint(0,9)], data_shape=data_shape)\n",
    "            test_metrics = model.test_on_batch(\n",
    "                X_test, Y_test, sample_weight=None, reset_metrics=False, return_dict=True\n",
    "            )\n",
    "        \n",
    "            if conf_tracking==1:\n",
    "                wandb.log({\"test_loss\": test_metrics['loss']})\n",
    "                wandb.log({\"batch_loss\": train_metrics['loss']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84443250",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    model_path,\n",
    "    overwrite=False,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None,\n",
    "    save_traces=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def0ecb",
   "metadata": {},
   "source": [
    "# Loading the Quiz data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_object= DataLoader(\n",
    "    quiz_directory,\n",
    "    quiz_training_folder,\n",
    ")\n",
    "quiz_train = quiz_object.LoadQuizData_info()\n",
    "X,image_order = quiz_object.Load_batch_quiz(quiz_train,data_shape=data_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab7204",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prds = model.predict(X)\n",
    "final_prd = np.column_stack((image_order,prds))\n",
    "final_ordered = final_prd[final_prd[:, 0].argsort()]\n",
    "df = pd.DataFrame(final_ordered, columns = ['image_id','angle','speed'])\n",
    "df = df.astype({'image_id': 'int32'})\n",
    "df.to_csv('transfer_MobileNetV3Small.csv', index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7d1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de125774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
